\section{Design}\label{sec:design}
When vectorizing arithmetic circuits with an SLP-style approach, at each step, we look at all available scalar instructions (whose source operands have all been scheduled), pick the largest set with the same operation, and schedule them together.
This na\"ive strategy makes no guarantees about values being computed and used on the same lane; in other words, lining the computation up on incurs arbitrarily many shuffles.
Unlike in normal vectorization, where applying arbitrary permutations to the lanes is relatively cheap, in FHE we are only allowed to rotate the entire vector by a fixed number of slots, and this rotation operation is expensive.
Hence, the cost of bookkeeping quickly outweighs whatever benefit we might get from vectorization, making this approach not worth it.

When trying to vectorize
%\raghav{Terminology things once again: I need a word for ``vertical alignment'' that isn't ``schedule'', since I want to use ``schedule'' to refer to the combination of vertical {\em and} horizontal alignment\dots} 
an FHE program, we have two optimization problems to solve: instruction scheduling, and data layout.
Optimizing only for instruction scheduling gives us the SLP approach: aggressively pack together isomorphic instructions without worrying about the incurred data movement overhead.
Optimizing for data layout places us on the other end of the spectrum: to avoid having to do any rotates, we must place each connected component of the circuit on a single lane, precluding any vectorization and forcing us to execute everything as scalar operations.

One of our key insights is that these two problems are highly related, so we have to solve these {\em simultaneously} rather than independently, attempting to choose an optimal point in the tradeoff space between the two ends of the spectrum.
In the following sections, we lay out the exact optimization problem as well as how we search for a solution. 

\subsection{Overview}
%\raghav{How's this?}
The input to the compilation process is an arithmetic circuit, represented as a directed acyclic graph (DAG), where each vertex corresponds to an operation (gate) in the circuit and the leaves (vertices with no children) correspond to the inputs, and there is an arc $v_1 \to v_2$ if $v_1$ consumes $v_2$. 
When a particular input is used multiple times in the circuit, it can either be represented as a single vertex with an incoming arc from every gate that consumes it, or it can be {\em replicated} into multiple vertices which each get consumed once.
This choice is expressed by the programmer in the surface language (Section~\ref{sec:surface-language}).

The vector {\em pre-schedule}\footnote{This structure is referred to as a {\em pre-schedule} to distinguish it from the actual vector schedule, which explicitly computes an alignment for sequences of instructions at the same level. %\raghav{does this make sense?}
} is a labeled quotient of the original circuit graph, where each vertex represents a connected subgraph, and is labeled with an integer representing the lane the subgraph gets placed on, such that no two vertices at the same height are labeled by the same lane.
The pre-schedule is naturally bi-graded into {\em epochs}, or groups of (independent) vertices at the same height which get packed together into a single sequence of vector instructions requiring no data movement, as well as {\em columns}, groups of vertices assigned to the same lane representing computation that happens in a single thread with no internal vectorization.
% Note that the uniqueness condition stated above means that each vertex of the quotient graph can be uniquely identified by its epoch and column (although the converse in general does not hold, since its possible to have a column that does not contain every epoch and vice-versa).

It turns out that both of our extremes from earlier can be realized in this model.
Aggressively vectorizing SLP-style can be recovered by assigning a trivial subcircuit to each vertex of the quotient, and simply enumerating lanes across epochs.
On the other end of the spectrum, we could instead quotient the circuit into the discrete graph of its connected components and assign each discrete vertex an arbitrary lane; since this graph has no edges it requires no rotations, but also precludes any vectorization within connected components.

Finding a good pre-schedule then requires us to first compute a ``good'' quotient that trades off between these extremes, together with a lane assignment that somehow maximizes our ability to vectorize without incurring too many rotations.
This is expressed in the search procedure {\system} uses when finding a vector schedule: an outer loop performs a best-first search over possible quotient graphs, and an inner loop uses simulated annealing on each quotient to find a good lane placement.
The result of the search procedure is a quotient of the circuit and a lane placement for the quotient, which together minimize\footnote{relative to the other quotients and lane placements visited in the search} the cost of the resulting vector schedule. %\raghav{how is this (including the footnote)?}
The next section discusses this search procedure in more detail.
% The next section discusses what makes one graph quotient ``better'' than another, and exactly how these tradeoffs are quantified.

\subsection{Schedule Search}\label{sec:schedule-search}
Given a cost model, we use a two-layer optimization strategy to produce a schedule that has good packing properties without incurring too much data movement overhead.
\subsubsection*{Determining lane placement}
\begin{algorithm}[t]
    \SetKwFunction{placelanes}{PlaceLanes}
    \SetKwFunction{naive}{InitialPlacement}
    \SetKwFunction{permute}{GenerateCandidate}
    \SetKwFunction{cost}{Cost}
    \SetKwFunction{accept}{Accept}
    
    \SetKwProg{algo}{Algorithm}{}{}
    \SetKwProg{proc}{Procedure}{}{}

    \algo{\placelanes{graph}}{
        $lanes \gets \naive{graph}$\;
        $T \gets T_0$\;
        $cost \gets \cost{lanes, graph}$\;
        \For{$i = 1 : N$}{
            $T \gets T / (1 + \beta T)$\;
            $candidate \gets \permute{lanes, graph}$\;
            $cost' \gets \cost{candidate, graph}$\;
            \If{$\accept{cost, cost', T}$}{
                $lanes\gets candidate$\;
                $cost \gets cost'$\;
            }
        }
        \Return{lanes, cost}
    }
    \proc{\cost{lanes, graph}}{
        $rotations[*] \gets \emptyset$\;
        \ForEach{$(u\to v) \in graph$}{
            \If{$lanes[u]\neq lanes[v]$}{
                $rotations[u.epoch] \gets rotations[u.epoch]\cup \{lanes[v] - lanes[u]\}$\;
            }
        }
        $instrs[*]\gets 0$\;
        \ForEach{$epoch \in graph$}{
            \ForEach{$opcode$}{
                $instr[opcode] \gets instr[opcode] + \max\limits_{col}count(epoch, col, opcode)$\;
            }
        }
        \Return{$w_R\times\sum\limits_{ep} rotations[ep] + \sum\limits_{op} w_{op}\times instrs[op]$}
    }
    \caption{Lane placement}\label{alg:lane-placement}
    
\end{algorithm}
The inner layer uses simulated annealing to find an optimal lane assignment for a given quotient graph.
The initial assignment is the naive one given by simply enumerating the vertices at each epoch.
At each step of the algorithm, we generate a candidate solution by randomly choosing two columns and a subset of the epochs in them to swap, maintaining the uniqueness condition of the schedule.
If the overall cost (as described in Section~\ref{sec:cost-model})
% \footnote{We could have chosen to only look at the rotation cost of each solution, but considering both costs helps prioritize lane placements with a heterogeneity of instruction types within each lane} 
of the candidate solution is lower than the original cost, it is accepted, and used as the starting point for the next round.
If the candidate solution cost is {\em higher} than the original cost, it is accepted with a probability that varies negatively with the difference in cost, and is generally smaller in later rounds than in earlier rounds\footnote{We use a slow cooling schedule with initial temperature $T_0=50$ and cooling parameter $\beta=10^{-3}$. The probability of accepting a move that increases the cost by $\Delta_c$ is $e^{-\Delta_c/T}$. The annealing is run for $20$k rounds.}.
After a fixed number of rounds have elapsed (see footnote), this algorithm returns the best solution found so far.

\subsubsection*{Computing optimal circuit quotient}
\begin{algorithm}[t]
    \SetKwFunction{quotient}{ComputeQuotient}
    \SetKwFunction{placelanes}{PlaceLanes}
    \SetKwFunction{accept}{Accept}
    \SetKwFunction{contract}{ContractEdge}
    \SetKwFunction{condensation}{Condensation}
    \SetKwFunction{cross}{CrossArcs}
    \SetKwFunction{enq}{Enqueue}
    \SetKwFunction{deq}{Dequeue}

    \SetKwProg{algo}{Algorithm}{}{}

    \algo{\quotient{graph}}{
        $lanes, cost \gets \placelanes{graph}$\;
        $best \gets lanes, graph$\;
        $bestcost \gets cost$\;
        $pqueue\gets []$\;
        $\enq{pqueue, (graph, lanes), cost}$\;
        \For{$i = 1 : N$}{
            $graph, lanes \gets \deq(pqueue)$\;
            \If{$arc \samplefrom \cross{graph}$}{
                $candidate \gets \condensation{\contract{graph, arc}}$\;
                $lanes', cost' \gets \placelanes{candidate}$\;
                $\enq{pqueue, (candidate, lanes'), cost'}$\;
                \If{$cost' < bestcost$}{
                    $best \gets lanes', candidate$\;
                }
                $\enq{pqueue, (graph, lanes), cost}$\;
            }
        }
        \Return{best}
    }
    \caption{Computing a good circuit quotient}\label{alg:circuit-quotient}
\end{algorithm}
The outer layer searches the space of quotients for a graph that admits a good lane placement without giving up too much vectorizability.
Here, we use a priority queue to implement a simple best-first search.
Each graph in the queue is assumed to already be equipped with an optimal lane placement, via the algorithm described above.
At each step, a graph is dequeued, and a new candidate solution is generated by looking at its set of cross-lane arcs and choosing one to contract (removing the edge and identifying its endpoints into a single vertex).
The contracted graph may not be acyclic, so we continue contracting cycles until it is (in effect computing the condensation). %\raghav{better?} %first mod out by all cycles before running the lane placement algorithm again.\milind{It's not clear what ``mod out by all cycles'' means -- add more meat here...}
The candidate solution is then enqueued with a priority based on its cost from the annealed lane placement.
If there are more available arcs to contract, the original graph is enqueued again.

After a fixed number of rounds have elapsed, or once the queue is empty, the algorithm terminates and returns the best graph.
Since each step of this algorithm involves an expensive call to the lane placement procedure, this runs for a much smaller number of rounds, usually between 150 and 200.
In practice, this is enough to find highly efficient schedules.

The next section discusses what makes one graph quotient or lane assigment ``better'' than another, and how these tradeoffs are quantified in \system's cost model.

\subsection{Cost Model}\label{sec:cost-model}
The cost of a particular pre-schedule comes from two places: the number of rotations we have to perform, and the amount we have ``given up'' on vectorizing.
\subsubsection*{Rotations}
Given a vector schedule, each {\em cross-lane arc} in the graph (an arc connecting vertices of different lanes) represents a rotation that must be performed to align an output from the tail of the arc to where it gets used at the head.
However, determining the rotation overhead is not as simple as counting these arcs.
Consider the case where instructions $A$ and $B$ are operands to instructions $A'$ and $B'$, respectively.
If $A$ and $B$ are assigned lanes $n$ and $m$, $A'$ and $B'$ are assigned $n+k$ and $m+k$, and $A$ and $B$ end up packed together in the same vector instruction, the two separate data movement operations required for the $A\to A'$ arc and the $B\to B'$ can actually be performed by a single rotation by $k$ (in fact, taking advantage of this fact is the main way \system optimizes data layout to require fewer total rotates). 
To compute the {\em actual} number of required rotations, we instead proceed epoch-by-epoch. 
For each epoch, we look at all cross-lane arcs with tails in that epoch, and compute the number of columns each spans (i.e. the required rotation amount) by subtracting the lane at the tail from the lane at the head.
The rotation cost for that epoch is then just the number of distinct rotation amounts.
For example, if a particular epoch has five cross-lane arcs, of which three represent a rotation of $-1$ and two represent a rotation of $6$, its rotation cost is $2$.
It follows that the total rotation cost of a schedule is the sum of the rotation costs of each epoch.

\subsubsection*{Vectorizability}
Taking successive quotients of the circuit reduces the total number of edges, and by extension, reduces the number of rotates that might be required; however, it also precludes any vectorization within the collapsed subcircuits.
To account for this, we need a way of quantifying the amount of vectorization we are ``giving up'' with each quotient.

Unfortunately, directly computing the opportunity cost is very messy: the amount of vectorization we give up by identifying a set of vertices is not a property local to the vertices, but rather requires us to look globally at {\em all possible vertices} in those epochs, to see which vectorization opportunities are no longer available after the identification.
Instead, we use an estimated {\em schedule height} as a proxy, with the justification being that giving up a lot of vectorization generally results in taller, less efficient final schedules. 
%\milind{this is good.}\raghav{Is it enough to say this? Or do I need to justify it further? Or should I remove these paragraphs entirely and just directly describe the schedule height computation?}

The schedule height computation once again proceeds epoch-by-epoch.
For each epoch, we estimate the minimum number of vector instructions required after packing by taking the maximum number of each type of operation across all the subcircuits associated to the vertices in that epoch.
For example, the estimated height of an epoch containing one vertex with 3 adds and 2 multiplies and another vertex with 2 adds and 4 multiplies would be 3 adds and 4 multiplies.

\subsubsection*{Overall Cost}
The analysis presented above computes an estimate for the number of each type of instruction in the generated vector program.
The final cost used a linear combination of all of these, with weights determined empirically by how expensive each instruction type is relative to the rest.
In our implementation, we scale rotates and multiplies by $1$, and addition and subtraction by $0.1$. 
%\raghav{Should this last sentence go here, or in implementation? Or both?}\milind{Both is good.}

\subsection{Instruction Alignment}\label{sec:instruction-alignment}
%\raghav{I just lifted this from the old version, is it still good or do we need to update it?}
We align the instructions corresponding to the subcircuits in each epoch to produce a final vector schedule.
% Given a set of subcircuits to compute in a single epoch of the program, we can align the instructions between subcircuits to actually produce a vector schedule.
It may seem like the solution to this is just sequence alignment, but aligning circuits is actually more complicated.
At each step, the number of available children to align roughly doubles, meaning that the total number of subproblems to solve is exponential in the depth instead of linear. 
This causes the dynamic programming strategy of sequence alignment to quickly blow up.

Instead of wrangling so many subproblems, we can formulate this as an ILP.
We create a variable for each scalar instruction representing its {\em schedule slot}, or the time at which it executes.
We add constraints to require that each instruction be scheduled after all of its dependences, and also that two instructions with different operations never be scheduled at the same time. 
Finally, to speed up the search for a solution, we place a bound on the total length of the schedule which is iteratively tightened until the solver returns ``unsatisfiable'', meaning no shorter schedule could be found. % (so the most recent one was the shortest).

\subsection{Data Layout}\label{sec:data-layout}
The circuit obtained after vectorization necessarily operates on inputs that have been ``packed'' into vectors.
Choosing a good layout within these vectors is crucial, since a poor choice of layout could incur many additional rotations to line operands up with where they are used.
{\system} can automatically select a good layout as part of the vectorization process.
An input that is only used once is placed on the lane within its vector corresponding to the unique lane where it is used, and any two inputs that are placed on the same lane by this rule are packed into separate input vectors to avoid collisions.

For inputs that are used multiple times (or inputs that are required to be packed into the same vector, e.g. elements of the same matrix), {\system} places a no-op ``load'' gate in the scalar circuit (so that the input is only used once, by the load gate).
Two load gates are placed in the same epoch in the circuit if and only if their corresponding inputs are required to be packed together (thus ensuring that they are given different lanes).
The layout for these inputs is then determined by the lanes chosen for their corresponding load gates.
This determines the data layout, as each input is placed on the same lane as its corresponding load gate (Section~{\ref{sec:using-coyote}}). %\milind{forward reference to 5.1 for how this can be overriden}
% The layout for these inputs is then determined by the lanes chosen for their corresponding load gates. \raghav{I could explain this better, but I'm not sure how.}
